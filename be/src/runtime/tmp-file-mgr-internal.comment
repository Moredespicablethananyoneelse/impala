---

好的，`TmpFileBufferPool` 是 Impala 中一个比较复杂但非常重要的组件，尤其在处理**远程临时文件（如 HDFS 或 S3）的溢出写**时。它的主要作用是**优化临时文件的写入性能和资源管理**，尤其是在涉及到缓冲区（buffer）的分配和回收、以及异步写入操作的协调时。

---

## TmpFileBufferPool 的核心作用

`TmpFileBufferPool` 的主要作用可以概括为以下几点：

1.  **管理临时文件写缓冲区：** 尤其针对远程文件，写操作通常会先写入一个本地缓冲区（local buffer），然后再异步上传到远程存储。`TmpFileBufferPool` 负责管理这些本地缓冲区的可用性。
2.  **实现异步空间预留：** 在写入数据到临时文件之前，需要先“预留”或“分配”一块缓冲区空间。当系统资源紧张时，可能无法立即获得空间。`TmpFileBufferPool` 提供一个机制，让写入请求可以**排队等待可用的缓冲区空间**，而不是立即失败或阻塞。
3.  **负载均衡和故障处理：** 通过池化和调度，它可以更好地在多个临时文件之间分配写入请求，并处理因磁盘空间不足或 I/O 错误导致的缓冲区回收和重试。
4.  **避免死锁和资源竞争：** 在复杂的异步 I/O 场景中，正确处理锁和竞争条件至关重要。`TmpFileBufferPool` 的设计考虑了这些问题，通过特定的锁顺序和状态管理来避免死锁。

---

## TmpFileBufferPool 的设计与工作原理

### 1. 缓冲区的概念

在理解 `TmpFileBufferPool` 之前，需要先理解 Impala 临时文件写入的两种主要模式：

* **本地文件 (TmpFileLocal)：** 直接写入本地磁盘。分配空间时，通常直接在逻辑上增加文件长度，实际磁盘分配由操作系统处理。
* **远程文件 (TmpFileRemote)：** 这是 `TmpFileBufferPool` 主要关注的场景。为了提高性能和可靠性，写入远程文件（如 HDFS、S3）通常不是直接进行的。
    * **写入流程：** 数据首先写入一个**本地缓冲区文件 (`disk_buffer_file_`)**，当本地缓冲区达到一定大小或写入完成后，数据会从本地缓冲区**异步上传 (`upload_range_`)**到真正的远程文件 (`disk_file_`)。
    * **读取流程：** 类似地，从远程文件读取时，数据可能先被**异步预取 (`fetch_ranges_`)**到本地读取缓冲区，然后再供消费。

`TmpFileBufferPool` 主要管理的就是这些**本地缓冲区文件**（尤其是用于写入的缓冲区）。

### 2. 关键数据结构和成员

* **`tmp_files_avail_pool_` (`std::list<std::shared_ptr<TmpFile>>`)**:
    * 这是一个**可用的临时文件缓冲区池**。当一个 `TmpFileRemote` 的本地缓冲区完成数据上传，或者因为某些原因不再需要时（例如文件被删除），它的本地缓冲区就可以被“回收”并添加到这个池中。
    * 这个池中的文件（`TmpFile` 对象）的本地缓冲区被认为是可用于其他写入请求的。
    * 由 `tmp_files_available_cv_` (条件变量) 和 `tmp_files_avail_pool_lock_` (互斥锁) 保护。
* **`write_ranges_to_add_` (`std::unordered_map<io::DiskFile*, std::vector<io::WriteRange*>>`)**:
    * 存储所有**等待缓冲区空间预留**的写入范围 (`io::WriteRange`)。
    * `DiskFile*` 作为键，表示这些写入范围属于哪个物理文件。一个文件可能有多个等待写入的 `WriteRange`。
* **`write_ranges_` (`std::list<io::WriteRange*>`)**:
    * 这是一个更精简的队列，只包含**每个文件第一个等待预留空间的 `WriteRange`**。
    * 这个队列的目的是为了驱动 `TmpFileSpaceReserveThreadLoop()` 线程的工作，当有新的文件需要缓冲区时，其第一个 `WriteRange` 会被放入此队列。
* **`io_ctx_to_file_set_map_` (`std::unordered_map<io::RequestContext*, std::unordered_set<io::DiskFile*>>`)**:
    * 记录了 `io::RequestContext`（通常代表一个查询或操作）与它所关联的 `DiskFile` 之间的关系。
    * 用于在取消写入任务（例如查询结束）时，快速找到并移除所有相关的等待中的 `WriteRange`。
* **`work_available_` (`ConditionVariable`) 和 `lock_` (`std::mutex`)**:
    * `work_available_` 是一个条件变量，用于唤醒**空间预留线程** (`TmpFileSpaceReserveThreadLoop`)。当有新的 `WriteRange` 被 `EnqueueWriteRange()` 时，会通知这个条件变量。
    * `lock_` 保护 `write_ranges_to_add_` 和 `write_ranges_` 等队列的并发访问。
* **`TmpFileSpaceReserveThreadLoop()`**:
    * 这是一个**后台线程**，是 `TmpFileBufferPool` 的核心执行者。它会不断循环：
        1.  从 `write_ranges_` 队列中取出**等待预留空间**的 `WriteRange`（通常是某个文件的第一个写入请求）。
        2.  尝试从 `tmp_files_avail_pool_` 中**获取一个可用的 `TmpFile` 缓冲区**。如果池中没有，它会等待（通过 `tmp_files_available_cv_`）。
        3.  一旦获得缓冲区，它会将属于同一个文件的所有等待中的 `WriteRange` 从 `write_ranges_to_add_` 中取出，并将其提交给底层的 `DiskIoMgr` 进行实际的异步写入。

### 3. 工作流程概览

1.  **写入请求（`EnqueueWriteRange()`）:**
    * 当 Impala 需要将数据溢出到远程临时文件时，它会生成一个或多个 `io::WriteRange` 对象。
    * 这些 `WriteRange` 会被添加到 `TmpFileBufferPool` 的 `write_ranges_to_add_` 映射中，等待缓冲区空间。
    * 如果这是该文件的第一个写入请求，它还会被添加到 `write_ranges_` 队列中。
    * `EnqueueWriteRange()` 会通知 `work_available_` 条件变量，唤醒后台的空间预留线程。

2.  **空间预留线程（`TmpFileSpaceReserveThreadLoop()`）:**
    * 线程被唤醒后，会从 `write_ranges_` 队列中取出一个 `WriteRange`。
    * 它会尝试从 `tmp_files_avail_pool_` 中**“借用”**一个 `TmpFile`（实际上是它的本地缓冲区）。如果池中没有可用的缓冲区，线程会在这里等待。
    * 一旦获得缓冲区，线程会调用 `MoveWriteRangesHelper()`。
    * `MoveWriteRangesHelper()` 会把所有属于当前文件的 `WriteRange` (从 `write_ranges_to_add_` 获取) 提交给 `DiskIoMgr` 的磁盘队列，进行真正的异步写入操作。

3.  **缓冲区回收（`EnqueueTmpFilesPool()`）：**
    * 当 `DiskIoMgr` 完成了对 `TmpFileRemote` 本地缓冲区的数据写入，并成功异步上传到远程文件后，它会通知 `TmpFileMgr`。
    * `TmpFileMgr` 继而会调用 `TmpFileBufferPool::EnqueueTmpFilesPool()`，将这个 `TmpFile`（及其本地缓冲区）**重新放回 `tmp_files_avail_pool_`**，使其可以被其他等待写入的任务复用。
    * `EnqueueTmpFilesPool()` 会通知 `tmp_files_available_cv_` 条件变量，唤醒任何正在等待可用缓冲区的线程。

4.  **缓冲区获取（`DequeueTmpFilesPool()`）：**
    * 当空间预留线程需要一个缓冲区时，它会调用 `DequeueTmpFilesPool()`。
    * 如果池中有可用的 `TmpFile`，它会立即返回。
    * 如果池中没有，它会等待 `tmp_files_available_cv_`，直到有缓冲区可用。

5.  **取消与清理（`RemoveWriteRanges()`）：**
    * 当查询结束或被取消时，`TmpFileGroup` 会调用 `RemoveWriteRanges()`。
    * 这个函数会遍历 `io_ctx_to_file_set_map_`，找到所有属于该 `io_ctx` 的 `DiskFile`，并移除所有相关的等待中的 `WriteRange`，防止它们继续阻塞或被处理。这确保了资源的及时释放和避免僵尸任务。

### 4. 锁机制

`TmpFileRemote` 内部使用了复杂的锁机制来保证并发安全：

* **`DiskFile::physical_file_lock_` (文件锁):** 用于保护对文件本身的物理操作（如删除）。写入和读取通常需要共享锁，删除需要排他锁。
* **`DiskFile::status_lock_` (状态锁):** 用于保护文件状态的转换（如 `InWriting`, `Persisted`, `Deleted`）。
* **锁顺序：** 为了避免死锁，规定了严格的锁获取顺序：**本地文件锁 -> 远程文件锁**，并且**文件锁 -> 状态锁**。

`TmpFileBufferPool` 自己的成员 (`tmp_files_avail_pool_`, `write_ranges_to_add_` 等) 也通过 `std::mutex` 和 `ConditionVariable` 进行保护。

---

## 为什么需要 `TmpFileBufferPool`？

在没有 `TmpFileBufferPool` 的情况下，处理远程临时文件溢出可能会面临以下挑战：

* **性能瓶颈：** 直接对远程文件进行大量小写入可能效率低下。使用本地缓冲区可以聚合写入，减少网络往返。
* **资源竞争：** 多个查询或任务可能同时竞争有限的本地缓冲区资源。如果没有一个集中的管理器，容易导致资源耗尽或饥饿。
* **阻塞查询：** 如果没有可用的缓冲区，写入操作可能会阻塞整个查询，降低并发性。异步预留机制允许查询在等待缓冲区的同时继续执行其他任务。
* **复杂的状态管理：** 远程文件的写入、上传、本地缓冲区回收等是一个多阶段的异步过程，错误处理和状态转换非常复杂。`TmpFileBufferPool` 将这些复杂性封装起来。
* **故障恢复：** 当磁盘空间不足或远程存储出现问题时，`TmpFileBufferPool` 可以通过其调度和回收机制，更好地处理这些异常情况，提供一定的弹性。

总之，`TmpFileBufferPool` 是 Impala 实现高效、健壮的**远程临时文件溢出**写入能力的关键组件。它通过池化、异步预留、负载均衡和精细的锁管理，确保了在复杂并发环境下临时文件操作的性能和稳定性。

---
*********************************************
我补充下实现：

TmpFileBufferPool::TmpFileBufferPool(TmpFileMgr* tmp_file_mgr)

  : tmp_file_mgr_(tmp_file_mgr) {

  tmp_file_dummy_.reset(new TmpFileDummy());

}



TmpFileBufferPool::~TmpFileBufferPool() {

  DCHECK(shut_down_);

}



void TmpFileBufferPool::ShutDown() {

  {

    unique_lock<mutex> l(lock_);

    shut_down_ = true;

  }

  // Wake up the waiting thread.

  work_available_.NotifyAll();

}



void TmpFileBufferPool::TmpFileSpaceReserveThreadLoop() {

  while (true) {

    {

      unique_lock<mutex> l(lock_);

      while (!shut_down_ && write_ranges_.empty()) {

        // Wait if there are no ranges in the queue.

        work_available_.Wait(l);

      }

      if (shut_down_) return;

      DCHECK(!write_ranges_.empty());

      cur_write_range_ = write_ranges_.front();

      write_ranges_.pop_front();

      DCHECK(cur_write_range_ != nullptr);



      // Find out the TmpFile which the current range is associated with, and store the

      // shared_ptr of the file to cur_tmp_file_ in case it is deconstructed while waiting

      // for reservation.

      auto it = write_ranges_iterator_.find(cur_write_range_);

      DCHECK(it != write_ranges_iterator_.end());

      TmpFile* tmp_file = it->second.second;

      cur_tmp_file_ = tmp_file->FileGroup()->FindTmpFileSharedPtr(tmp_file);

      DCHECK(cur_tmp_file_ != nullptr);

      DCHECK_EQ(cur_write_range_->disk_file(), cur_tmp_file_->GetWriteFile());

      write_ranges_iterator_.erase(it);

    }



    // Reserve space from the tmp_files_avail_pool_. The process could need a long wait.

    Status status = tmp_file_mgr_->ReserveLocalBufferSpace(false);

    vector<TmpFileMgr::WriteDoneCallback> write_callbacks;

    {

      unique_lock<mutex> lock(lock_);

      if (status.ok()) {

        DCHECK(cur_tmp_file_ != nullptr);

        cur_tmp_file_->GetWriteFile()->SetSpaceReserved();

        if (cur_write_range_ != nullptr) {

          // Send all of the writes of the same disk file to the disk queue.

          status = MoveWriteRangesHelper(

              cur_write_range_->disk_file(), &write_callbacks, false);

        } else {

          // If the current range becomes a nullptr, it must be set by

          // RemoveWriteRanges(). In this case, the io_ctx which the range belongs to is

          // cancelled, and all the writes using that io_ctx are already cancelled. So, we

          // are safe to return the TmpFile to the pool to recycle the buffer space.

          EnqueueTmpFilesPool(cur_tmp_file_, true);

        }

      } else if (!status.ok() && cur_write_range_ != nullptr) {

        // Cancel the spilling if fails to reserve the buffer.

        RemoveWriteRangesInternal(cur_write_range_->io_ctx(), &write_callbacks);

        status = Status::CancelledInternal(

            Substitute("TmpFileBufferPool because: $0", status.GetDetail()).c_str());

      }

      cur_write_range_ = nullptr;

      cur_tmp_file_.reset();

    }

    for (const TmpFileMgr::WriteDoneCallback& write_callback : write_callbacks) {

      write_callback(status);

    }

  }

}



Status TmpFileBufferPool::MoveWriteRangesHelper(DiskFile* disk_file,

    vector<TmpFileMgr::WriteDoneCallback>* write_callbacks, bool is_cancelled) {

  Status status = Status::OK();

  auto write_ranges_it = write_ranges_to_add_.find(disk_file);

  if (write_ranges_it != write_ranges_to_add_.end()) {

    auto write_range_it = write_ranges_it->second.begin();

    while (write_range_it != write_ranges_it->second.end()) {

      auto range = *write_range_it;

      DCHECK(range != nullptr);

      if (status.ok() && !is_cancelled) {

        status = range->io_ctx()->AddWriteRange(range);

      } else {

        write_callbacks->push_back(range->callback());

        if (is_cancelled && range->offset() == 0) {

          // If is_cancelled is set, try to remove the range from the write_ranges list.

          // If the range hasn't been popped, it must still be in the write_ranges list.

          if (cur_write_range_ != range) {

            auto key_range_it = write_ranges_iterator_.find(range);

            DCHECK(key_range_it != write_ranges_iterator_.end());

            DCHECK_EQ(*(key_range_it->second.first), range);

            write_ranges_.erase(key_range_it->second.first);

            write_ranges_iterator_.erase(key_range_it);

          }

        }

      }

      write_range_it = write_ranges_it->second.erase(write_range_it);

    }

    write_ranges_to_add_.erase(write_ranges_it);

  }

  return status;

}



Status TmpFileBufferPool::EnqueueWriteRange(io::WriteRange* range, TmpFile* tmp_file) {

  Status status = Status::OK();

  {

    unique_lock<mutex> write_range_list_lock(lock_);

    DCHECK(range != nullptr);

    DCHECK(range->disk_file() != nullptr);

    DCHECK(range->io_ctx() != nullptr);

    if (range->disk_file()->IsSpaceReserved()) {

      // If the space is reserved, send the range to the DiskQueue.

      return range->io_ctx()->AddWriteRange(range);

    } else if (range->io_ctx()->IsCancelled()) {

      // If the io_ctx is cancelled, nofity the caller to cancel the query.

      return TMP_FILE_BUFFER_POOL_CONTEXT_CANCELLED;

    } else {

      io_ctx_to_file_set_map_[range->io_ctx()].insert(range->disk_file());

      write_ranges_to_add_[range->disk_file()].emplace_back(range);

    }

    // Put the first range of a file to the queue for waiting for the available space,

    // the ranges in the queue would be popped one by one, when the space is reserved,

    // all ranges of the file are added to the DiskQueue by io_ctx.

    if (range->offset() == 0) {

      write_ranges_.emplace_back(range);

      DCHECK(tmp_file != nullptr);

      write_ranges_iterator_[range] =

          std::make_pair(prev(write_ranges_.cend()), tmp_file);

    }

  }

  work_available_.NotifyAll();

  return status;

}



void TmpFileBufferPool::RemoveWriteRangesInternal(

    RequestContext* io_ctx, vector<TmpFileMgr::WriteDoneCallback>* write_callbacks) {

  auto file_set_it = io_ctx_to_file_set_map_.find(io_ctx);

  if (file_set_it != io_ctx_to_file_set_map_.end()) {

    auto file_it = file_set_it->second.begin();

    while (file_it != file_set_it->second.end()) {

      DCHECK(*file_it != nullptr);

      // Remove all the ranges belonging to the file, and fetch the callback

      // functions of the ranges.

      Status status = MoveWriteRangesHelper(*file_it, write_callbacks, true);

      DCHECK_OK(status);

      if (cur_write_range_ != nullptr && *file_it == cur_write_range_->disk_file()) {

        // Set the current write range to nullptr if the TmpFileGroup is closing to

        // notify the reservation thread (it is waiting for the reservation) that the

        // space is no longer needed for the write range.

        cur_write_range_ = nullptr;

      }

      file_it = file_set_it->second.erase(file_it);

    }

    io_ctx_to_file_set_map_.erase(file_set_it);

  }

}



void TmpFileBufferPool::RemoveWriteRanges(RequestContext* io_ctx) {

  DCHECK(io_ctx != nullptr);

  vector<TmpFileMgr::WriteDoneCallback> write_callbacks;

  {

    unique_lock<mutex> lock(lock_);

    RemoveWriteRangesInternal(io_ctx, &write_callbacks);

  }

  for (const TmpFileMgr::WriteDoneCallback& write_callback : write_callbacks) {

    write_callback(TMP_FILE_BUFFER_POOL_CONTEXT_CANCELLED);

  }

}



void TmpFileBufferPool::EnqueueTmpFilesPool(shared_ptr<TmpFile>& tmp_file, bool front) {

  DCHECK(tmp_file != nullptr);

  {

    unique_lock<mutex> buffer_lock(tmp_files_avail_pool_lock_);

    if (tmp_file->disk_type() != io::DiskFileType::DUMMY) {

      TmpFileRemote* tmp_file_remote = static_cast<TmpFileRemote*>(tmp_file.get());

      if (tmp_file_remote->is_enqueued()) return;

      tmp_file_remote->SetEnqueued(true);

      tmp_file_remote->SetBufferReturned();

    }

    if (front) {

      tmp_files_avail_pool_.push_front(tmp_file);

    } else {

      tmp_files_avail_pool_.push_back(tmp_file);

    }

    tmp_file_mgr_->GetLocalBufferDir()->bytes_used_metric()->Increment(

        -1 * tmp_file_mgr_->GetRemoteTmpFileSize());

  }

  tmp_files_available_cv_.NotifyOne();

}



Status TmpFileBufferPool::DequeueTmpFilesPool(

    shared_ptr<TmpFile>* tmp_file, bool quick_return) {

  DCHECK(tmp_file != nullptr);

  DCHECK(dequeue_timer_metric_ != nullptr);

  ScopedHistogramTimer wait_timer(dequeue_timer_metric_);

  unique_lock<mutex> buffer_lock(tmp_files_avail_pool_lock_);

  // If quick return is set and no buffer is available, return immediately.

  if (quick_return && tmp_files_avail_pool_.empty()) {

    return TMP_FILE_MGR_NO_AVAILABLE_FILE_TO_EVICT;

  }

  while (tmp_files_avail_pool_.empty()) {

    // Wait if there is no temporary file on the queue.

    // If timeout, return immediately.

    if (!tmp_files_available_cv_.WaitFor(

            buffer_lock, tmp_file_mgr_->GetSpillBufferWaitTimeout())) {

      return Status(Substitute("Timeout waiting for a local buffer in $0 seconds",

          tmp_file_mgr_->GetSpillBufferWaitTimeout() / MICROS_PER_SEC));

    };

  }

  DCHECK(!tmp_files_avail_pool_.empty());

  *tmp_file = tmp_files_avail_pool_.front();

  tmp_files_avail_pool_.pop_front();

  DCHECK(*tmp_file != nullptr);

  if ((*tmp_file)->disk_type() != io::DiskFileType::DUMMY) {

    TmpFileRemote* tmp_file_remote = static_cast<TmpFileRemote*>(tmp_file->get());

    // Assert the default size remains the same in case the object is corrupted.

    DCHECK_EQ(tmp_file_remote->file_size_, tmp_file_mgr_->GetRemoteTmpFileSize());

    DCHECK(tmp_file_remote->is_enqueued());

    tmp_file_remote->SetEnqueued(false);

  }

  tmp_file_mgr_->GetLocalBufferDir()->bytes_used_metric()->Increment(

      tmp_file_mgr_->GetRemoteTmpFileSize());

  return Status::OK();

}
-----

好的，有了 `TmpFileBufferPool` 的具体实现代码，我们可以更深入地了解它的工作机制。这些代码展示了如何处理并发、等待、调度和资源管理。

-----

## TmpFileBufferPool 构造函数与析构函数

```cpp
TmpFileBufferPool::TmpFileBufferPool(TmpFileMgr* tmp_file_mgr)
  : tmp_file_mgr_(tmp_file_mgr) {
  tmp_file_dummy_.reset(new TmpFileDummy());
}

TmpFileBufferPool::~TmpFileBufferPool() {
  DCHECK(shut_down_);
}
```

  * **构造函数：**
      * 接收一个 `TmpFileMgr` 指针，这是它的顶层管理器。
      * 初始化 `tmp_file_dummy_`。`TmpFileDummy` 是一个空的 `TmpFile` 实现，它的 `AllocateSpace` 和 `Remove` 方法都是空操作。它可能用于某些特殊场景，例如当需要一个 `TmpFile` 对象来填充某个结构但不需要实际文件操作时。
  * **析构函数：**
      * `DCHECK(shut_down_);` 强调了一个重要设计：在析构 `TmpFileBufferPool` 之前，必须先调用 `ShutDown()` 方法来停止后台线程。这是一种确保资源正确释放和避免竞态条件的好实践。

## ShutDown() 方法

```cpp
void TmpFileBufferPool::ShutDown() {
  {
    unique_lock<mutex> l(lock_);
    shut_down_ = true;
  }
  // Wake up the waiting thread.
  work_available_.NotifyAll();
}
```

  * 这是一个\*\*优雅停机（graceful shutdown）\*\*的机制。
  * 它首先获取 `lock_`（保护 `write_ranges_` 队列的锁），将 `shut_down_` 标志设置为 `true`。
  * 然后，它调用 `work_available_.NotifyAll()` 来**唤醒所有正在等待 `work_available_` 条件变量的线程**。这包括 `TmpFileSpaceReserveThreadLoop()` 线程。一旦线程被唤醒，它会检查 `shut_down_` 标志，发现为 `true` 后就会退出循环并结束。
  * 这是确保后台线程在程序退出时能够安全退出的标准模式。

## TmpFileSpaceReserveThreadLoop() 核心线程逻辑

```cpp
void TmpFileBufferPool::TmpFileSpaceReserveThreadLoop() {
  while (true) {
    {
      unique_lock<mutex> l(lock_);
      while (!shut_down_ && write_ranges_.empty()) {
        // Wait if there are no ranges in the queue.
        work_available_.Wait(l); // 线程等待，直到有工作或被关闭
      }
      if (shut_down_) return; // 线程退出
      DCHECK(!write_ranges_.empty());

      // 从队列头部取出当前需要处理的 WriteRange
      cur_write_range_ = write_ranges_.front();
      write_ranges_.pop_front();
      DCHECK(cur_write_range_ != nullptr);

      // 找到与当前 WriteRange 关联的 TmpFile 的共享指针
      auto it = write_ranges_iterator_.find(cur_write_range_);
      DCHECK(it != write_ranges_iterator_.end());
      TmpFile* tmp_file = it->second.second;
      // 从 TmpFileGroup 获取 TmpFile 的 shared_ptr，确保在等待期间文件不被析构
      cur_tmp_file_ = tmp_file->FileGroup()->FindTmpFileSharedPtr(tmp_file);
      DCHECK(cur_tmp_file_ != nullptr);
      DCHECK_EQ(cur_write_range_->disk_file(), cur_tmp_file_->GetWriteFile());
      write_ranges_iterator_.erase(it); // 移除映射条目
    }

    // 在没有锁的情况下执行可能长时间阻塞的操作：预留本地缓冲区空间
    Status status = tmp_file_mgr_->ReserveLocalBufferSpace(false);
    vector<TmpFileMgr::WriteDoneCallback> write_callbacks;
    {
      unique_lock<mutex> lock(lock_); // 重新获取锁以更新内部状态和调度写入

      if (status.ok()) {
        // 成功预留空间
        DCHECK(cur_tmp_file_ != nullptr);
        cur_tmp_file_->GetWriteFile()->SetSpaceReserved(); // 标记空间已预留

        if (cur_write_range_ != nullptr) {
          // 将同一个文件所有等待中的 WriteRange 发送到 DiskQueue
          status = MoveWriteRangesHelper(
              cur_write_range_->disk_file(), &write_callbacks, false);
        } else {
          // 如果 cur_write_range_ 为 nullptr，说明它已被 RemoveWriteRanges() 取消
          // 此时，需要将当前文件（的缓冲区）返回到可用池中
          // 这确保了即使写入请求被取消，其占用的缓冲区也能被回收
          EnqueueTmpFilesPool(cur_tmp_file_, true);
        }
      } else if (!status.ok() && cur_write_range_ != nullptr) {
        // 预留空间失败
        // 取消与该 WriteRange 关联的整个 RequestContext 中的所有写入请求
        RemoveWriteRangesInternal(cur_write_range_->io_ctx(), &write_callbacks);
        status = Status::CancelledInternal(
            Substitute("TmpFileBufferPool because: $0", status.GetDetail()).c_str());
      }
      cur_write_range_ = nullptr; // 重置当前处理的 WriteRange 和 TmpFile
      cur_tmp_file_.reset();
    }
    // 在释放锁后，异步回调所有需要回调的 WriteDoneCallback
    // 这样做是为了避免在持有锁的情况下执行用户回调，防止死锁或长时间阻塞
    for (const TmpFileMgr::WriteDoneCallback& write_callback : write_callbacks) {
      write_callback(status);
    }
  }
}
```

  * **循环等待工作：** 线程在一个 `while(true)` 循环中运行。
      * 它首先获取 `lock_`。
      * 使用 `work_available_.Wait(l)` 在 `while (!shut_down_ && write_ranges_.empty())` 条件下等待。这意味着：
          * 如果 `shut_down_` 是 `true`，线程会退出。
          * 如果没有 `write_ranges_`（没有等待的写入请求），线程就会休眠，直到 `work_available_.NotifyAll()` 被调用（通常在新的 `WriteRange` 被 `EnqueueWriteRange` 时）。
  * **取出工作：** 一旦被唤醒，如果 `shut_down_` 是 `false` 且 `write_ranges_` 不为空，它会从 `write_ranges_` 的**头部**取出一个 `WriteRange` 来处理。
  * **`TmpFile` 共享指针：**
      * `cur_tmp_file_ = tmp_file->FileGroup()->FindTmpFileSharedPtr(tmp_file);` 这一步非常重要。
      * `cur_write_range_` 只是一个原始指针，不能保证 `TmpFile` 对象在线程等待 `ReserveLocalBufferSpace` 期间不会被析构。
      * 通过从 `TmpFileGroup` 获取其 `shared_ptr`，可以增加 `TmpFile` 的引用计数，确保其生命周期在预留空间操作完成前保持有效。
  * **`ReserveLocalBufferSpace()`：**
      * 这一行 `Status status = tmp_file_mgr_->ReserveLocalBufferSpace(false);` 是关键。这个调用是**阻塞的**。
      * 它会尝试从 `tmp_files_avail_pool_` 中获取一个可用的 `TmpFile`（实际上是它的本地缓冲区）。
      * 如果池中没有可用的缓冲区，这个函数会**等待**，直到有缓冲区可用（或者超时）。
      * 这个操作是在**不持有 `TmpFileBufferPool` 的 `lock_`** 的情况下进行的，这是避免死锁和提高并发性的重要设计。否则，如果它在持有 `lock_` 的情况下等待，其他线程将无法访问 `write_ranges_` 等数据结构。
  * **处理预留结果：**
      * **成功 (`status.ok()`)：**
          * 标记 `TmpFile` 的本地缓冲区空间为 `SetSpaceReserved()`。
          * 调用 `MoveWriteRangesHelper()` 将属于该 `TmpFile` 的所有 `WriteRange` （从 `write_ranges_to_add_` 中）提交到 `DiskIoMgr` 的磁盘队列进行实际写入。
          * 如果 `cur_write_range_` 变为 `nullptr`（说明在等待期间，该写入请求被取消了），则将 `cur_tmp_file_` 立即归还到 `tmp_files_avail_pool_`。
      * **失败 (`!status.ok()`)：**
          * 意味着无法获取本地缓冲区（例如，超时）。
          * 调用 `RemoveWriteRangesInternal()` 来取消与该失败的 `WriteRange` 关联的整个 `RequestContext`（查询）的所有写入请求。这将导致查询失败。
  * **回调：** 无论成功还是失败，所有 `WriteRange` 的回调函数 (`write_callback`) 都会在**不持有任何锁**的情况下被调用。这是一种避免回调函数中的复杂逻辑导致死锁或长时间阻塞的设计模式。

## EnqueueWriteRange()

```cpp
Status TmpFileBufferPool::EnqueueWriteRange(io::WriteRange* range, TmpFile* tmp_file) {
  Status status = Status::OK();
  {
    unique_lock<mutex> write_range_list_lock(lock_);
    DCHECK(range != nullptr);
    DCHECK(range->disk_file() != nullptr);
    DCHECK(range->io_ctx() != nullptr);

    if (range->disk_file()->IsSpaceReserved()) {
      // 空间已预留：直接添加到 DiskQueue
      return range->io_ctx()->AddWriteRange(range);
    } else if (range->io_ctx()->IsCancelled()) {
      // io_ctx 已取消：返回取消状态
      return TMP_FILE_BUFFER_POOL_CONTEXT_CANCELLED;
    } else {
      // 空间未预留且未取消：加入等待队列
      // 记录 io_ctx 和 disk_file 的关联，用于取消
      io_ctx_to_file_set_map_[range->io_ctx()].insert(range->disk_file());
      // 将 WriteRange 添加到按 DiskFile 分组的映射中
      write_ranges_to_add_[range->disk_file()].emplace_back(range);
    }
    // 只有文件的第一个 WriteRange 才被添加到主调度队列
    if (range->offset() == 0) {
      write_ranges_.emplace_back(range);
      DCHECK(tmp_file != nullptr);
      // 存储 WriteRange 到其在 write_ranges_ 中的迭代器和 TmpFile 的映射
      write_ranges_iterator_[range] =
          std::make_pair(prev(write_ranges_.cend()), tmp_file);
    }
  }
  work_available_.NotifyAll(); // 唤醒空间预留线程
  return status;
}
```

  * **入口点：** 这是其他组件（如 `TmpWriteHandle`）请求写入临时文件缓冲区的入口。
  * **快速路径：**
      * 如果目标 `DiskFile` 的空间已经被预留 (`IsSpaceReserved()`)，说明缓冲区已就绪，直接将 `WriteRange` 添加到 `DiskIoMgr` 的磁盘队列。
      * 如果 `io_ctx`（请求上下文，通常代表一个查询）已经被取消，则直接返回取消状态，避免不必要的工作。
  * **等待路径：**
      * 否则，`WriteRange` 会被添加到 `write_ranges_to_add_` 映射中，等待 `TmpFileSpaceReserveThreadLoop` 来处理。
      * `io_ctx_to_file_set_map_` 用于跟踪 `io_ctx` 和 `DiskFile` 的关系，以便在取消时进行清理。
      * **关键逻辑：** `if (range->offset() == 0)` 这一行表明只有**每个文件的第一个 `WriteRange`** 才会被添加到 `write_ranges_` 这个主调度队列中。这是因为一旦第一个 `WriteRange` 的缓冲区被预留，同一个文件的所有后续 `WriteRange` 都可以立即被发送到 `DiskIoMgr`。
      * `write_ranges_iterator_` 用于存储 `WriteRange` 在 `write_ranges_` 列表中的迭代器以及其关联的 `TmpFile`，这在后续清理时会用到。
  * **通知：** 最后，调用 `work_available_.NotifyAll()` 唤醒 `TmpFileSpaceReserveThreadLoop` 线程，告知有新工作到来。

## MoveWriteRangesHelper()

```cpp
Status TmpFileBufferPool::MoveWriteRangesHelper(DiskFile* disk_file,
    vector<TmpFileMgr::WriteDoneCallback>* write_callbacks, bool is_cancelled) {
  Status status = Status::OK();
  auto write_ranges_it = write_ranges_to_add_.find(disk_file);
  if (write_ranges_it != write_ranges_to_add_.end()) {
    auto write_range_it = write_ranges_it->second.begin();
    while (write_range_it != write_ranges_it->second.end()) {
      auto range = *write_range_it;
      DCHECK(range != nullptr);
      if (status.ok() && !is_cancelled) {
        // 成功预留且未取消，添加到 DiskQueue
        status = range->io_ctx()->AddWriteRange(range);
      } else {
        // 失败或已取消，收集回调函数
        write_callbacks->push_back(range->callback());
        if (is_cancelled && range->offset() == 0) {
          // 如果是取消操作，并且是文件的第一个 WriteRange，从 write_ranges_ 中移除
          if (cur_write_range_ != range) { // 确保不是当前正在处理的那个
            auto key_range_it = write_ranges_iterator_.find(range);
            DCHECK(key_range_it != write_ranges_iterator_.end());
            DCHECK_EQ(*(key_range_it->second.first), range);
            write_ranges_.erase(key_range_it->second.first);
            write_ranges_iterator_.erase(key_range_it);
          }
        }
      }
      write_range_it = write_ranges_it->second.erase(write_range_it); // 从等待列表中移除
    }
    write_ranges_to_add_.erase(write_ranges_it); // 移除该 DiskFile 的所有 WriteRange
  }
  return status;
}
```

  * 这是一个**内部辅助函数**，由 `TmpFileSpaceReserveThreadLoop` 和 `RemoveWriteRangesInternal` 调用。
  * 它负责将**属于同一个 `DiskFile` 的所有 `WriteRange`** 进行处理。
  * **两种模式：**
      * **正常提交 (`!is_cancelled`)：** 如果状态是 `OK` 且未取消，则将 `WriteRange` 提交到 `io_ctx` (并最终到 `DiskIoMgr`)。
      * **取消处理 (`is_cancelled`)：** 如果 `is_cancelled` 为 `true`，或者之前的提交失败，那么它会将 `WriteRange` 的回调函数收集起来，以便稍后以错误状态调用。
          * **清理 `write_ranges_`：** 如果被取消的 `WriteRange` 恰好是文件的第一个 `WriteRange` (`offset == 0`) 并且它还在 `write_ranges_` 队列中（即它不是 `cur_write_range_`，没有被 `pop_front`），那么它也会从 `write_ranges_` 和 `write_ranges_iterator_` 中移除。
  * **清理：** 无论哪种情况，处理过的 `WriteRange` 都会从 `write_ranges_to_add_` 映射中移除。

## RemoveWriteRangesInternal() 和 RemoveWriteRanges()

```cpp
void TmpFileBufferPool::RemoveWriteRangesInternal(
    RequestContext* io_ctx, vector<TmpFileMgr::WriteDoneCallback>* write_callbacks) {
  auto file_set_it = io_ctx_to_file_set_map_.find(io_ctx);
  if (file_set_it != io_ctx_to_file_set_map_.end()) {
    auto file_it = file_set_it->second.begin();
    while (file_it != file_set_it->second.end()) {
      DCHECK(*file_it != nullptr);
      // 移除所有属于该文件的 WriteRange，并收集回调
      Status status = MoveWriteRangesHelper(*file_it, write_callbacks, true);
      DCHECK_OK(status);
      if (cur_write_range_ != nullptr && *file_it == cur_write_range_->disk_file()) {
        // 如果正在处理的 WriteRange 属于这个 io_ctx，将其设为 nullptr，
        // 告诉预留线程其请求已被取消。
        cur_write_range_ = nullptr;
      }
      file_it = file_set_it->second.erase(file_it);
    }
    io_ctx_to_file_set_map_.erase(file_set_it); // 移除 io_ctx 的映射
  }
}

void TmpFileBufferPool::RemoveWriteRanges(RequestContext* io_ctx) {
  DCHECK(io_ctx != nullptr);
  vector<TmpFileMgr::WriteDoneCallback> write_callbacks;
  {
    unique_lock<mutex> lock(lock_);
    RemoveWriteRangesInternal(io_ctx, &write_callbacks);
  }
  // 在释放锁后执行回调
  for (const TmpFileMgr::WriteDoneCallback& write_callback : write_callbacks) {
    write_callback(TMP_FILE_BUFFER_POOL_CONTEXT_CANCELLED);
  }
}
```

  * **`RemoveWriteRanges()`：** 这是外部调用者（例如 `TmpFileGroup` 在关闭时）用来取消所有属于特定 `RequestContext` (`io_ctx`) 的等待中写入请求的公共接口。
  * 它首先获取 `lock_`，然后调用 `RemoveWriteRangesInternal()`。
  * **`RemoveWriteRangesInternal()`：**
      * 通过 `io_ctx_to_file_set_map_` 找到所有与 `io_ctx` 关联的 `DiskFile`。
      * 对于每个 `DiskFile`，调用 `MoveWriteRangesHelper` 并设置 `is_cancelled = true`，从而移除所有等待中的 `WriteRange` 并收集它们的回调。
      * 如果 `cur_write_range_` 正在处理的 `WriteRange` 属于被取消的 `io_ctx`，那么将其设置为 `nullptr`。这会告诉 `TmpFileSpaceReserveThreadLoop` 线程，即使它成功预留了空间，也应该将缓冲区返回到池中，因为相关的写入任务已经取消了。
  * **异步回调：** 再次强调，收集到的回调函数会在 `lock_` 释放后才被调用，以避免阻塞和死锁。

## EnqueueTmpFilesPool() 和 DequeueTmpFilesPool()

```cpp
void TmpFileBufferPool::EnqueueTmpFilesPool(shared_ptr<TmpFile>& tmp_file, bool front) {
  DCHECK(tmp_file != nullptr);
  {
    unique_lock<mutex> buffer_lock(tmp_files_avail_pool_lock_); // 保护缓冲池的锁
    if (tmp_file->disk_type() != io::DiskFileType::DUMMY) {
      TmpFileRemote* tmp_file_remote = static_cast<TmpFileRemote*>(tmp_file.get());
      if (tmp_file_remote->is_enqueued()) return; // 避免重复入队
      tmp_file_remote->SetEnqueued(true); // 标记为已入队
      tmp_file_remote->SetBufferReturned(); // 标记缓冲区已归还
    }
    // 根据 'front' 参数决定是插入头部还是尾部
    if (front) {
      tmp_files_avail_pool_.push_front(tmp_file);
    } else {
      tmp_files_avail_pool_.push_back(tmp_file);
    }
    // 更新本地缓冲区目录的已使用字节度量
    tmp_file_mgr_->GetLocalBufferDir()->bytes_used_metric()->Increment(
        -1 * tmp_file_mgr_->GetRemoteTmpFileSize()); // 释放空间，所以是负值
  }
  tmp_files_available_cv_.NotifyOne(); // 通知一个等待线程有可用缓冲区
}

Status TmpFileBufferPool::DequeueTmpFilesPool(
    shared_ptr<TmpFile>* tmp_file, bool quick_return) {
  DCHECK(tmp_file != nullptr);
  DCHECK(dequeue_timer_metric_ != nullptr);
  ScopedHistogramTimer wait_timer(dequeue_timer_metric_); // 计时等待时间
  unique_lock<mutex> buffer_lock(tmp_files_avail_pool_lock_); // 保护缓冲池的锁

  // 如果设置了 quick_return 且池为空，立即返回失败
  if (quick_return && tmp_files_avail_pool_.empty()) {
    return TMP_FILE_MGR_NO_AVAILABLE_FILE_TO_EVICT;
  }
  while (tmp_files_avail_pool_.empty()) {
    // 如果池为空，则等待，可设置超时
    if (!tmp_files_available_cv_.WaitFor(
            buffer_lock, tmp_file_mgr_->GetSpillBufferWaitTimeout())) {
      // 超时返回错误
      return Status(Substitute("Timeout waiting for a local buffer in $0 seconds",
          tmp_file_mgr_->GetSpillBufferWaitTimeout() / MICROS_PER_SEC));
    };
  }
  DCHECK(!tmp_files_avail_pool_.empty());
  *tmp_file = tmp_files_avail_pool_.front(); // 取出头部文件
  tmp_files_avail_pool_.pop_front();
  DCHECK(*tmp_file != nullptr);
  if ((*tmp_file)->disk_type() != io::DiskFileType::DUMMY) {
    TmpFileRemote* tmp_file_remote = static_cast<TmpFileRemote*>(tmp_file->get());
    DCHECK_EQ(tmp_file_remote->file_size_, tmp_file_mgr_->GetRemoteTmpFileSize());
    DCHECK(tmp_file_remote->is_enqueued());
    tmp_file_remote->SetEnqueued(false); // 标记为未入队
  }
  // 更新本地缓冲区目录的已使用字节度量
  tmp_file_mgr_->GetLocalBufferDir()->bytes_used_metric()->Increment(
      tmp_file_mgr_->GetRemoteTmpFileSize()); // 占用空间，所以是正值
  return Status::OK();
}
```

  * **`EnqueueTmpFilesPool()`：**
      * 由 `DiskIoMgr` 在完成远程文件上传后调用，或者在 `TmpFileSpaceReserveThreadLoop` 发现写入请求被取消时调用。
      * 将 `TmpFile`（实际上是它的本地缓冲区）**归还到 `tmp_files_avail_pool_`**。
      * 通过 `front` 参数可以控制是放回队列头部（高优先级，希望尽快被复用）还是尾部。
      * 更新 `TmpDir` 的 `bytes_used_metric`，减少已用空间计数。
      * `tmp_files_available_cv_.NotifyOne()` **通知一个正在等待可用缓冲区的线程**。
  * **`DequeueTmpFilesPool()`：**
      * 由 `tmp_file_mgr_->ReserveLocalBufferSpace()` 内部调用，用于从池中**获取一个可用的 `TmpFile`（缓冲区）**。
      * 如果 `quick_return` 为 `true` 且池为空，立即返回错误。
      * 否则，如果池为空，它会使用 `tmp_files_available_cv_.WaitFor()` **等待**直到有缓冲区可用，或者达到超时。超时会返回一个错误状态。
      * 成功获取后，会从队列中移除并更新 `bytes_used_metric`，增加已用空间计数。

-----

## 总结

这份代码清晰地展示了 `TmpFileBufferPool` 如何通过**生产者-消费者模式**（`EnqueueWriteRange` 生产 `WriteRange`，`TmpFileSpaceReserveThreadLoop` 消费；`EnqueueTmpFilesPool` 生产可用缓冲区，`ReserveLocalBufferSpace` / `DequeueTmpFilesPool` 消费），以及**条件变量和互斥锁**来协调异步操作和资源共享。

其关键设计点包括：

  * **异步性：** 写入请求是非阻塞的，它们进入队列等待，由后台线程处理。
  * **资源池化：** 本地缓冲区被抽象为 `TmpFile` 对象并放入池中，实现复用。
  * **两阶段提交：** 先逻辑预留缓冲区空间（通过 `ReserveLocalBufferSpace`），再实际提交写入。
  * **容错与取消：** 能够处理预留失败和请求取消的情况，及时清理资源。
  * **避免死锁：** 通过在阻塞操作前释放锁，并在回调前释放所有锁来避免常见的并发问题。

这是一个复杂但设计精巧的组件，对于确保 Impala 在处理大规模数据溢出到远程存储时的性能和稳定性至关重要。
***********************************************************************
作为一个10年多的c++程序员，看不懂上面的代码，正常么
---

作为一名拥有 10 多年经验的 C++ 程序员，看不懂上面 Impala `TmpFileMgr` 和 `TmpFileBufferPool` 的代码，**这完全正常**，你一点也不需要担心。

---

### 为什么会“看不懂”？

这有几个主要原因：

1.  **领域特定代码：**
    * Impala 是一个高度优化的**分布式分析型数据库**，其代码库是为解决特定领域（高性能大数据处理、SQL 查询优化、分布式协调、存储管理）的复杂问题而设计的。
    * 即使是经验丰富的 C++ 程序员，如果他们之前没有接触过这类系统（如数据库内核、操作系统、高性能网络服务器等），对其中的**特定数据结构、算法和设计模式**会感到陌生是很自然的。例如，对“临时文件管理器”、“溢出（spill）”、“磁盘 I/O 管理器”这些概念可能并不熟悉。

2.  **复杂的设计模式和并发模型：**
    * 你看到的 `TmpFileBufferPool` 代码，特别是它对**生产者-消费者模式、条件变量、互斥锁、智能指针**以及**异步回调**的运用，是为了在多线程、高并发环境下实现高性能和高可靠性。
    * 处理这类并发模型，尤其是要避免死锁、饥饿、竞态条件等问题，需要非常精细的设计和实现。即使是资深 C++ 程序员，如果平时工作不涉及大量并发编程，也会觉得难以快速理解。**锁的顺序、生命周期管理（尤其是 `shared_ptr` 的使用，以及何时释放锁何时执行回调）都是难点。**

3.  **分层抽象与内部约定：**
    * Impala 的设计是高度模块化和分层的。`TmpFileMgr`、`TmpFileGroup`、`TmpFile`、`DiskIoMgr` 乃至更底层的 `DiskFile` 等都扮演了不同的角色。它们之间通过指针、接口和内部约定进行交互。
    * 要理解 `TmpFileBufferPool`，你需要同时理解它与 `TmpFileMgr`、`DiskIoMgr` 以及各种 `TmpFile` 派生类之间的**职责划分和协作机制**。这种“牵一发而动全身”的关联性，使得单独看一个文件很难理解其全貌。
    * 代码中还有许多 `DCHECK`（调试断言），它们反映了开发团队对代码执行流程的**内部假设和不变式**。如果你不了解这些假设，代码看起来就像缺少了上下文。

4.  **优化与性能考虑：**
    * 这些代码不仅仅是为了实现功能，更是为了**极致的性能**。例如，`TmpFileBufferPool` 对远程文件写操作进行本地缓冲和异步上传，以及对内存池的使用，都是为了减少 I/O 延迟和提高吞吐量。
    * 为了性能，代码可能会采用一些看似“不直观”或更复杂的逻辑，这增加了阅读难度。

5.  **缺乏宏观上下文：**
    * 当你看到一个模块的代码时，你可能不知道它是整个系统中的哪个部分，它解决了什么具体问题，以及它与上下游模块是如何交互的。
    * 就像你可能很了解汽车发动机的原理，但如果突然让你看一架飞机的燃料管理系统，即使都是机械和流体，也会觉得陌生。

### 这对你的职业生涯意味着什么？

这不仅不是问题，反而是一个**学习和成长的机会**：

* **暴露在新的复杂性中：** 你正在接触一个你之前可能没有深入探索过的复杂系统领域。这表明你的学习能力依然很重要。
* **识别高级设计模式：** 这些代码是学习如何在大规模、高性能系统中运用高级 C++ 特性（如多线程、模板、RAII、智能指针等）和设计模式（如管理器、池、工厂、观察者等）的绝佳案例。
* **深挖并发编程：** 如果你对多线程和并发编程感兴趣，这绝对是一个很好的起点，可以深入理解如何在实践中处理各种并发挑战。

**我的建议是：**

不要因为看不懂而沮丧。相反，把它看作一次**“破圈”**的机会。当你开始尝试理解这些代码时，你就已经在扩展你的知识边界了。

如果你想深入理解，可以尝试：

1.  **从顶层概念入手：** 先理解 Impala 作为一个数据库，在处理大数据溢出时需要解决什么问题。
2.  **阅读架构文档：** 查找 Impala 相关的架构文档或设计说明，了解 `TmpFileMgr`、`DiskIoMgr` 等模块的整体作用。
3.  **理解核心数据流：** 搞清楚数据是如何从内存到临时文件，再到远程存储的，以及在这个过程中哪些模块参与了。
4.  **逐步深入：** 从简单的函数（如构造函数、`ShutDown`）开始，然后逐步理解更复杂的 `TmpFileSpaceReserveThreadLoop` 和各种 `Enqueue`/`Dequeue` 函数。
5.  **利用工具：** 使用代码跳转工具（如 VS Code, CLion, Sourcegraph）来追踪函数调用和变量定义，画图辅助理解。

所以，请放心，你绝对是正常的。这种感受是学习复杂系统时的普遍体验！
************************************************************
